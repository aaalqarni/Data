{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Load_model_Reddit_bert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaalqarni/Data-/blob/master/Load_model_Reddit_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOJHvvL_gkPD",
        "outputId": "0128133b-e186-48d0-e861-6a9909f9ea41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive \n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6kzXGuOTjQY",
        "outputId": "67321ad6-b487-4808-9bc2-cbc6332d257a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xgawrStij8k",
        "outputId": "ddbb5803-434a-4c42-d1e4-d387203373c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd /content/drive/My Drive/group-5/Sarcasm/Dataset/Sarc_reddit_Khodak/\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/18jkhFxxAIhP43KeQN-eCjSicYYbVyecy/group-5/Sarcasm/Dataset/Sarc_reddit_Khodak\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uVOeslPi32F"
      },
      "source": [
        "! cd .."
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNFVUgQpUNjr",
        "outputId": "ad22c1dd-007d-4065-bbe4-94b9b799231a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "! ls "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 1309_36545_compressed_train-balanced-sarcasm.csv.zip\n",
            " authors.json\n",
            " authors.json.bz2\n",
            " Final_result.csv\n",
            " main\n",
            " model_reddit_cased_save\n",
            " model_reddit_cased_save_02\n",
            " model_REDDIT_large_cased_save\n",
            " model_REDDIT_save\n",
            " Multinomial_logit_Sarcasm.pkl\n",
            " Multinomial_Naive_Bayes.pkl\n",
            " Random_forest.pkl\n",
            "'readme (1).gdoc'\n",
            " readme.gdoc\n",
            " readme.txt\n",
            " Reddit_bert_model\n",
            " sarcasm_reddit_bert_model\n",
            " sarcasm_reddit_bert_model_02\n",
            " stats.json\n",
            " stats.json.bz2\n",
            " SVM.pkl\n",
            " test-balanced.csv\n",
            " test-balanced-sarcasm.csv\n",
            " train-balanced-sarcasm.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbygvpA6jC_d",
        "outputId": "106713f5-689d-4e9a-d75f-947ef0c6d043",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ti1waIzYW87"
      },
      "source": [
        "import json\n",
        "import pandas as pd \n",
        "import textwrap\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmBK3h8-X06Z"
      },
      "source": [
        "Data = pd.read_csv(\"train-balanced-sarcasm.csv\")\n",
        "Data['comment']= Data['comment'].astype(str)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUguNiFZX9nc",
        "outputId": "8116bb00-d401-4dfc-d393-428f605dbbff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "\n",
        "Data.head()\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NC and NH.</td>\n",
              "      <td>Trumpbart</td>\n",
              "      <td>politics</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-16 23:55:23</td>\n",
              "      <td>Yeah, I get that argument. At this point, I'd ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>You do know west teams play against west teams...</td>\n",
              "      <td>Shbshb906</td>\n",
              "      <td>nba</td>\n",
              "      <td>-4</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-11</td>\n",
              "      <td>2016-11-01 00:24:10</td>\n",
              "      <td>The blazers and Mavericks (The wests 5 and 6 s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>They were underdogs earlier today, but since G...</td>\n",
              "      <td>Creepeth</td>\n",
              "      <td>nfl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-09</td>\n",
              "      <td>2016-09-22 21:45:37</td>\n",
              "      <td>They're favored to win.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>This meme isn't funny none of the \"new york ni...</td>\n",
              "      <td>icebrotha</td>\n",
              "      <td>BlackPeopleTwitter</td>\n",
              "      <td>-8</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-18 21:03:47</td>\n",
              "      <td>deadass don't kill my buzz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>I could use one of those tools.</td>\n",
              "      <td>cush2push</td>\n",
              "      <td>MaddenUltimateTeam</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-12</td>\n",
              "      <td>2016-12-30 17:00:13</td>\n",
              "      <td>Yep can confirm I saw the tool they use for th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                     parent_comment\n",
              "0      0  ...  Yeah, I get that argument. At this point, I'd ...\n",
              "1      0  ...  The blazers and Mavericks (The wests 5 and 6 s...\n",
              "2      0  ...                            They're favored to win.\n",
              "3      0  ...                         deadass don't kill my buzz\n",
              "4      0  ...  Yep can confirm I saw the tool they use for th...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZPuFKtV3bam",
        "outputId": "01b60fa6-031f-4921-c6fd-06e0c93ca1ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install 'transformers==2.10'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==2.10\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/b5/ac41e3e95205ebf53439e4dd087c58e9fd371fd8e3724f2b9b4cdb8282e5/transformers-2.10.0-py3-none-any.whl (660kB)\n",
            "\r\u001b[K     |▌                               | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 6.3MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 7.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |██▌                             | 51kB 6.8MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 71kB 8.3MB/s eta 0:00:01\r\u001b[K     |████                            | 81kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 307kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 317kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 327kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 337kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 348kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 358kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 368kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 378kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 389kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 399kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 409kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 419kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 430kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 440kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 450kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 460kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 471kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 481kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 491kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 501kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 512kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 522kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 532kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 542kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 552kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 563kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 573kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 583kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 593kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 604kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 614kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 624kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 634kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 645kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 655kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 665kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.10) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 24.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.10) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 46.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==2.10) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.10) (1.18.5)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 55.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.10) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.10) (3.0.12)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.10) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.10) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=2bda6588dff91455ef6fc0126b403769599ffd79937de3c06ebb1628dfb73cad\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BOFHKC2-lDj"
      },
      "source": [
        "#%cd /content/drive/My Drive/group-5/Sarcasm/Dataset/sarcasm_v2_Oraby"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUIc3OSKyM-M",
        "outputId": "f4048bca-adc5-4fa7-e0ca-5032b98b3e0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "# load config\n",
        "# conf = BertConfig.from_pretrained('./sarcasm_discussion_bert_model/model_save', num_labels=2)\n",
        "# load a sequence model\n",
        "dir=\"/content/drive/My Drive/group-5/Sarcasm/Dataset/sarcasm_v2_Oraby/sarcasm_discussion_bert_model_2/model_save\"\n",
        "conf = BertConfig.from_pretrained(dir, num_labels=2)\n",
        "bsm = BertForSequenceClassification.from_pretrained(dir, config=conf)\n",
        "# get bert core model\n",
        "\n",
        "\n",
        "bsm.cuda()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49aMlKHSYZ12"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(Data, test_size=0.2)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSQo7rQbYdw_",
        "outputId": "ceb9faf7-9bf0-47a2-c218-93911ed0fb5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "test_data.info()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 202166 entries, 723977 to 86170\n",
            "Data columns (total 10 columns):\n",
            " #   Column          Non-Null Count   Dtype \n",
            "---  ------          --------------   ----- \n",
            " 0   label           202166 non-null  int64 \n",
            " 1   comment         202166 non-null  object\n",
            " 2   author          202166 non-null  object\n",
            " 3   subreddit       202166 non-null  object\n",
            " 4   score           202166 non-null  int64 \n",
            " 5   ups             202166 non-null  int64 \n",
            " 6   downs           202166 non-null  int64 \n",
            " 7   date            202166 non-null  object\n",
            " 8   created_utc     202166 non-null  object\n",
            " 9   parent_comment  202166 non-null  object\n",
            "dtypes: int64(4), object(6)\n",
            "memory usage: 17.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GZv9apiYi4M",
        "outputId": "0dcfc8ad-101f-4d86-9f11-20380803dc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "test_data"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>comment</th>\n",
              "      <th>author</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>score</th>\n",
              "      <th>ups</th>\n",
              "      <th>downs</th>\n",
              "      <th>date</th>\n",
              "      <th>created_utc</th>\n",
              "      <th>parent_comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>723977</th>\n",
              "      <td>0</td>\n",
              "      <td>Maybe take your own advice slick.</td>\n",
              "      <td>SwoleNole</td>\n",
              "      <td>baseball</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-04</td>\n",
              "      <td>2015-04-13 13:17:42</td>\n",
              "      <td>Be that as it may, they were a playoff team la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27054</th>\n",
              "      <td>0</td>\n",
              "      <td>Jaroslaw Kaczynski is retarded!</td>\n",
              "      <td>sixgears</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-11</td>\n",
              "      <td>2016-11-14 19:16:32</td>\n",
              "      <td>Poland exhumes president, others killed in 201...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>929143</th>\n",
              "      <td>0</td>\n",
              "      <td>It is though....</td>\n",
              "      <td>boilerrat</td>\n",
              "      <td>gaming</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2012-05</td>\n",
              "      <td>2012-05-31 23:08:54</td>\n",
              "      <td>THATS SO NOSTALGIC!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835037</th>\n",
              "      <td>0</td>\n",
              "      <td>I was just answering your question.</td>\n",
              "      <td>orangeslash</td>\n",
              "      <td>CFB</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-11</td>\n",
              "      <td>2013-11-18 15:54:07</td>\n",
              "      <td>Still can't lead with the crown of your helmet...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370740</th>\n",
              "      <td>1</td>\n",
              "      <td>Yay, another two weeks of Combine 24/7..</td>\n",
              "      <td>ABrokenOven</td>\n",
              "      <td>blackops3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-02</td>\n",
              "      <td>2016-02-06 01:33:55</td>\n",
              "      <td>They said we'd get it in a week or two. Calm y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329487</th>\n",
              "      <td>1</td>\n",
              "      <td>Yeah cause sci-fi movies with female leads are...</td>\n",
              "      <td>BurgerLaowai</td>\n",
              "      <td>TumblrInAction</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2016-08</td>\n",
              "      <td>2016-08-30 18:02:15</td>\n",
              "      <td>Single greatest meme in the history of man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>611332</th>\n",
              "      <td>0</td>\n",
              "      <td>Yeah cause who needs science and research right?</td>\n",
              "      <td>onepennytoomany</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-08</td>\n",
              "      <td>2015-08-23 15:46:25</td>\n",
              "      <td>Thousands of prehistoric mammoth tusks are bei...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810472</th>\n",
              "      <td>1</td>\n",
              "      <td>Much better if you continue to think they are ...</td>\n",
              "      <td>OmniStardust</td>\n",
              "      <td>PoliticalDiscussion</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>0</td>\n",
              "      <td>2013-11</td>\n",
              "      <td>2013-11-26 18:50:00</td>\n",
              "      <td>If I thought rich people were hoarding MY mone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21260</th>\n",
              "      <td>0</td>\n",
              "      <td>beautiful</td>\n",
              "      <td>RecklessBasterd</td>\n",
              "      <td>Dodgers</td>\n",
              "      <td>6</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-10</td>\n",
              "      <td>2016-10-14 02:42:42</td>\n",
              "      <td>Joc Pederson GONE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86170</th>\n",
              "      <td>1</td>\n",
              "      <td>Isn't that how Trump is gonna build the wall?</td>\n",
              "      <td>danielhickman</td>\n",
              "      <td>funny</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2016-11</td>\n",
              "      <td>2016-11-23 00:28:05</td>\n",
              "      <td>It offers to convert into other currancies, su...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>202166 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        label  ...                                     parent_comment\n",
              "723977      0  ...  Be that as it may, they were a playoff team la...\n",
              "27054       0  ...  Poland exhumes president, others killed in 201...\n",
              "929143      0  ...                               THATS SO NOSTALGIC!!\n",
              "835037      0  ...  Still can't lead with the crown of your helmet...\n",
              "370740      1  ...  They said we'd get it in a week or two. Calm y...\n",
              "...       ...  ...                                                ...\n",
              "329487      1  ...         Single greatest meme in the history of man\n",
              "611332      0  ...  Thousands of prehistoric mammoth tusks are bei...\n",
              "810472      1  ...  If I thought rich people were hoarding MY mone...\n",
              "21260       0  ...                                  Joc Pederson GONE\n",
              "86170       1  ...  It offers to convert into other currancies, su...\n",
              "\n",
              "[202166 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JVWS_9csm37"
      },
      "source": [
        "#dqube_test = pd.read_csv(\"/content/drive/My Drive/group-5/DQUBE_Processed.csv\",index_col=None)\n",
        "#dqube_test = dqube_test.iloc[:,[11,13]]\n",
        "#dqube_test.rename(columns={ dqube_test.columns[0]: \"sentence\", dqube_test.columns[1]: \"label\" }, inplace = True)\n",
        "#dqube_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHCqMQHSRb56"
      },
      "source": [
        "#%cd sarcasm_v2_Oraby"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDgSsvYQRdsW"
      },
      "source": [
        "#test_data =pd.read_csv(\"GEN-sarc-notsarc.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DErbJEkPRhzN"
      },
      "source": [
        "#test_data[\"class\"].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axNgMzxJSb-o"
      },
      "source": [
        "#test_data[\"class\"]=test_data[\"class\"].astype(str)\n",
        "\n",
        "#sarcasm = {'sarc': 1,'notsarc': 0} \n",
        "\n",
        "\n",
        "#test_data[\"class\"] = [sarcasm[item] for item in test_data[\"class\"]] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRkxgWX4SwbH"
      },
      "source": [
        "# valid_label=test_data[\"class\"]\n",
        "# Text=test_data[\"text\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlsMQBloYJqb"
      },
      "source": [
        "MAX_SEQ_LENGTH =500\n",
        "TRAIN_BATCH_SIZE =16\n",
        "NUM_TRAIN_EPOCHS = 3\n",
        "\n",
        "EVAL_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 5e-5\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(dir)\n",
        "\n",
        "\n",
        "# Report the number of sentences.\n",
        "# print('Number of test examples: {}'.format(len(dqube_test)))\n",
        "\n",
        "# Create sentence and label lists\n",
        "test = test_data.comment.values\n",
        "labels = test_data.label.values\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    #print(sent)\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = MAX_SEQ_LENGTH,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 8 \n",
        "\n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYoA1l2F8C6T",
        "outputId": "c0e1e41f-5dbe-4cc1-b689-a5aa39728311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Prediction on test set\n",
        "import torch.nn.functional as F \n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "bsm.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = bsm(b_input_ids, attention_mask=b_input_mask)\n",
        "              \n",
        "        \n",
        "  logits = outputs[0]\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  # Store predictions and true labels\n",
        "  # Concatenate logits from each batch\n",
        "  all_logits = torch.cat(outputs, dim=0)\n",
        "\n",
        "  # Apply softmax to calculate probabilities\n",
        "  probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "print('    DONE.')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 202,166 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm8dS2Kb-tfh",
        "outputId": "0894a663-d92b-4dd9-e8bf-347f222af3d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import f1_score,accuracy_score,average_precision_score,precision_score, recall_score\n",
        "import numpy as np\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "print(\"F1 score: {}\".format(precision_recall_fscore_support(flat_predictions, flat_true_labels, average='macro')))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: (0.5463555069513808, 0.5557784489627531, 0.5258289441171211, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FhXmlLpBg8a",
        "outputId": "3544917e-7d2a-4352-8886-47d65e1e7c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy: {}\".format(accuracy_score(flat_predictions, flat_true_labels)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.5454131753113778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozbrXfO1BjI4",
        "outputId": "25e91b10-f200-4e3c-c78e-e937dbbb03ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(\"F1 score: {}\".format(f1_score(flat_predictions, flat_true_labels, average='macro')))\n",
        "average_precision = average_precision_score(flat_predictions.reshape((-1)), flat_true_labels.reshape((-1)))\n",
        "precision=precision_score(flat_predictions.reshape((-1)), flat_true_labels.reshape((-1)),average=\"macro\")\n",
        "recall=recall_score(flat_predictions.reshape((-1)), flat_true_labels.reshape((-1)),average=\"macro\")\n",
        "print('precision-score: {0:0.2f}'.format(precision))\n",
        "print('Recall-score: {0:0.2f}'.format(recall))\n",
        "print(\"Accuracy: {}\".format(accuracy_score(flat_predictions, flat_true_labels)))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.5258289441171211\n",
            "precision-score: 0.55\n",
            "Recall-score: 0.56\n",
            "Accuracy: 0.5454131753113778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bztucxSsCx5a",
        "outputId": "151d825f-8eb9-47f6-b7bb-bdf2a8cbd269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(flat_true_labels,flat_predictions)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[34589, 66957],\n",
              "       [24945, 75675]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCYhGUFjF6Zs"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Combine the results across the batches.\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb1UFU6KKtOS"
      },
      "source": [
        "from scipy.special import softmax\n",
        "# Our performance metric for the test set.\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
        "\n",
        "prediction_logit = np.argmax(softmax(predictions, axis=1),axis=1)\n",
        "result = softmax(predictions, axis=1)\n",
        "positive_prob = result[:,1]\n",
        "pred_label = [1 if i > 0.5 else 0 for i in positive_prob]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJbrhkQKzhC",
        "outputId": "bf4e7443-ee1d-4cba-e083-909121a6aa66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Calculate the evaluation metrics accuracy, precision, recall and f1 score.\n",
        "accuracy = accuracy_score(true_labels, pred_label)\n",
        "print('Accuracy: ', accuracy)\n",
        "\n",
        "precision = precision_score(true_labels, pred_label)\n",
        "print(\"Precision: \", precision)\n",
        "\n",
        "recall = recall_score(true_labels, pred_label)\n",
        "print(\"Recall: \", recall)\n",
        "\n",
        "f1 = f1_score(true_labels, pred_label)\n",
        "print(\"F1 score: \", f1)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.5454131753113778\n",
            "Precision:  0.5305611643950866\n",
            "Recall:  0.7520870602265951\n",
            "F1 score:  0.6221942676730304\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUUGpkNtK28K",
        "outputId": "e18dc13b-3f24-4dba-fdd3-f5d6fae4d8fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Compute the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(true_labels,pred_label)\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[34589, 66957],\n",
              "       [24945, 75675]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXNkQHWkK7SC",
        "outputId": "6f8f8d1a-c12e-4406-c66d-f21bb5f30b5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "fpr, tpr, thresholds = roc_curve(true_labels, positive_prob)\n",
        "\n",
        "def plot_roc_curve(fpr,tpr,label=None):\n",
        "  plt.plot(fpr,tpr,linewidth=1.5, label=label)\n",
        "  plt.plot([0,1],[0,1],'r--')\n",
        "  plt.axis([0, 1, 0, 1])                                    \n",
        "  plt.xlabel('False Positive Rate (Fall-Out)', fontsize=16) \n",
        "  plt.ylabel('True Positive Rate (Recall)', fontsize=16)    \n",
        "  plt.grid(True)  \n",
        "  plt.xlim([0, 1])\n",
        "  plt.ylim([0, 1])\n",
        "  plt.title('Receiver Operating Characteristic')                                        \n",
        "\n",
        "plt.figure(figsize=(8, 6))  \n",
        "                  \n",
        "plot_roc_curve(fpr, tpr)\n",
        "           \n",
        "                       \n",
        "plt.show()\n",
        "print(\"AUC:\" , roc_auc_score(true_labels,pred_label))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.5463555069513808\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}